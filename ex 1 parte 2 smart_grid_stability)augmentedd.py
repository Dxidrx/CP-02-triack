import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, classification_report
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression

# ===========================================================
# 1. Carregar o conjunto de dados
# ===========================================================
df = pd.read_csv("smart_grid_stability_augmented.csv")
print("‚úÖ Dados carregados com sucesso!")
print(df.head(), "\n")

# ===========================================================
# 2. Separar vari√°veis independentes (X) e dependente (y)
# ===========================================================
# A coluna 'stabf' √© o alvo (Stable/Unstable)
X = df.drop(columns=["stabf"])
y = df["stabf"]

# Converter o target em 0 (est√°vel) e 1 (inst√°vel)
y = y.map({"stable": 0, "unstable": 1})

# ===========================================================
# 3. Dividir em treino e teste
# ===========================================================
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# ===========================================================
# 4. Padronizar as vari√°veis num√©ricas
# ===========================================================
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ===========================================================
# 5. Criar e treinar modelos
# ===========================================================
modelos = {
    "√Årvore de Decis√£o": DecisionTreeClassifier(random_state=42),
    "KNN": KNeighborsClassifier(n_neighbors=5),
    "Regress√£o Log√≠stica": LogisticRegression(max_iter=1000, random_state=42)
}

# Dicion√°rio para armazenar resultados
resultados = {}

for nome, modelo in modelos.items():
    modelo.fit(X_train_scaled, y_train)
    y_pred = modelo.predict(X_test_scaled)

    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    cm = confusion_matrix(y_test, y_pred)

    resultados[nome] = {"Acur√°cia": acc, "F1-score": f1, "Matriz": cm}

    print("=" * 60)
    print(f"üîπ Modelo: {nome}")
    print(f"Acur√°cia: {acc:.4f}")
    print(f"F1-score: {f1:.4f}")
    print("Matriz de Confus√£o:")
    print(cm)
    print("Relat√≥rio de Classifica√ß√£o:")
    print(classification_report(y_test, y_pred, target_names=["Est√°vel", "Inst√°vel"]))

# ===========================================================
# 6. Comparar resultados
# ===========================================================
print("\n" + "=" * 60)
print("üî∏ COMPARA√á√ÉO FINAL DOS MODELOS üî∏\n")
df_resultados = pd.DataFrame(resultados).T
print(df_resultados[["Acur√°cia", "F1-score"]])

melhor = df_resultados["F1-score"].idxmax()
print(f"\n‚úÖ Modelo mais confi√°vel para detectar instabilidade: {melhor}")